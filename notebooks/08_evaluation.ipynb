{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from core import load_csv_data, save_results, calculate_metrics, print_section\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "print_section(\"SYSTEM EVALUATION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b6bff7d",
   "metadata": {},
   "source": [
    "## Create Sample Train/Test Data\n",
    "\n",
    "For demonstration, create sample CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample train.csv\n",
    "train_data = {\n",
    "    'story_id': ['train_001', 'train_002', 'train_003'],\n",
    "    'novel_file': ['evermoor_sample.txt', 'evermoor_sample.txt', 'evermoor_sample.txt'],\n",
    "    'backstory': [\n",
    "        'Elizabeth lived in Paris before coming to Evermoor.',\n",
    "        'Thomas Blackwood arrived at Evermoor in 1842.',\n",
    "        'Elizabeth discovered secrets about her grandmother in 1820.'\n",
    "    ],\n",
    "    'label': [1, 0, 1]\n",
    "}\n",
    "\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.to_csv('../data/train.csv', index=False)\n",
    "\n",
    "# Create sample test.csv\n",
    "test_data = {\n",
    "    'story_id': ['test_001', 'test_002'],\n",
    "    'novel_file': ['evermoor_sample.txt', 'evermoor_sample.txt'],\n",
    "    'backstory': [\n",
    "        'Lord Edmund invited Elizabeth to solve a mystery.',\n",
    "        'Elizabeth met Thomas in London before 1847.'\n",
    "    ]\n",
    "}\n",
    "\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df.to_csv('../data/test.csv', index=False)\n",
    "\n",
    "print(\"✓ Created sample train/test files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bcb93e",
   "metadata": {},
   "source": [
    "## Evaluate on Training Set\n",
    "\n",
    "This would calibrate thresholds in real usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ae2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_samples = load_csv_data('../data/train.csv')\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_samples)}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sample in train_samples:\n",
    "    print(f\"ID: {sample['story_id']}\")\n",
    "    print(f\"  Backstory: {sample['backstory'][:60]}...\")\n",
    "    print(f\"  Label: {sample['label']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c486aa1",
   "metadata": {},
   "source": [
    "## Performance Metrics\n",
    "\n",
    "Calculate accuracy, precision, recall, F1 on training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ada3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate predictions (in real usage, run full pipeline)\n",
    "import pickle\n",
    "\n",
    "# For demo, use random predictions\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "train_predictions = [random.choice([0, 1]) for _ in train_samples]\n",
    "train_labels = [int(s['label']) for s in train_samples]\n",
    "\n",
    "# Calculate metrics\n",
    "metrics = calculate_metrics(train_predictions, train_labels)\n",
    "\n",
    "print(\"\\nTraining Set Metrics:\")\n",
    "print(\"=\" * 60)\n",
    "for metric, value in metrics.items():\n",
    "    print(f\"{metric.capitalize()}: {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ef8543",
   "metadata": {},
   "source": [
    "## Generate Test Predictions\n",
    "\n",
    "Run pipeline on test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_samples = load_csv_data('../data/test.csv')\n",
    "\n",
    "print(f\"\\nTest samples: {len(test_samples)}\")\n",
    "\n",
    "# Generate predictions (in production, run full pipeline for each)\n",
    "test_results = []\n",
    "\n",
    "for sample in test_samples:\n",
    "    # Simulate prediction\n",
    "    prediction = random.choice([0, 1])\n",
    "    confidence = random.uniform(0.6, 0.95)\n",
    "    rationale = f\"Based on analysis of novel and backstory. Score: {random.uniform(0.3, 0.7):.3f}\"\n",
    "    \n",
    "    test_results.append({\n",
    "        'story_id': sample['story_id'],\n",
    "        'prediction': prediction,\n",
    "        'confidence': confidence,\n",
    "        'rationale': rationale\n",
    "    })\n",
    "    \n",
    "print(f\"✓ Generated {len(test_results)} predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3a6b78",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2169a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to results.csv\n",
    "save_results(test_results, '../results/results.csv')\n",
    "\n",
    "print(\"\\n✓ Results saved to results.csv\")\n",
    "print(\"\\nSample predictions:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_df = pd.DataFrame(test_results)\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb0e9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n✓ Module 8 Complete: Evaluation finished!\")\n",
    "print(\"\\nTo use this system on real data:\")\n",
    "print(\"1. Place novels in data/novels/\")\n",
    "print(\"2. Update train.csv and test.csv\")\n",
    "print(\"3. Run run_pipeline.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
